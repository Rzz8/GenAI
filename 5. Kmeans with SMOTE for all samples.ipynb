{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245210cf-218d-4472-8a00-d88806d97a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Score for the test data: 1.5269311669346415\n",
      "Actual           0      1\n",
      "Prediction               \n",
      "0           303290  37093\n",
      "1            14342  33100\n",
      "2           131286  25208\n",
      "3               10      0\n",
      "4             5337  15910\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('combined_output.csv')\n",
    "df2 = df.drop(' Label', axis=1)\n",
    "df2 = df2.dropna()\n",
    "\n",
    "# Replace infinite values with NaN and drop rows with NaNs\n",
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df2_cleaned = df2.dropna()\n",
    "\n",
    "# Select only numeric columns, keeping 'Label Num' for later comparison\n",
    "numeric_df = df2_cleaned.select_dtypes(include=[np.number])\n",
    "\n",
    "# Extract the 'Label Num' for the ground truth comparison later\n",
    "labels = numeric_df['Label Num']\n",
    "\n",
    "# Drop 'Label Num' column from the features for clustering\n",
    "numeric_df = numeric_df.drop('Label Num', axis=1)\n",
    "\n",
    "# Convert to NumPy array and scale the data\n",
    "X = numeric_df.to_numpy()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_labels, y_test_labels = train_test_split(X_scaled, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Apply SMOTE to balance the classes in the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train_labels)\n",
    "\n",
    "# Define the pipeline with KMeans\n",
    "pipeline = Pipeline([\n",
    "    ('kmeans', KMeans())\n",
    "])\n",
    "\n",
    "# Setup the grid search parameters for KMeans\n",
    "param_grid = {\n",
    "    'kmeans__n_clusters': [5, 7, 9, 11],\n",
    "    'kmeans__n_init': [10, 20],\n",
    "    'kmeans__algorithm': ['lloyd', 'elkan']\n",
    "}\n",
    "\n",
    "# Davies-Bouldin score as the scoring metric\n",
    "def davies_bouldin_scorer(estimator, X):\n",
    "    labels = estimator.predict(X)\n",
    "    return -davies_bouldin_score(X, labels)  # Minimize Davies-Bouldin score\n",
    "\n",
    "# Initialize the grid search for KMeans clustering\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=davies_bouldin_scorer,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "# Perform grid search on the training dataset\n",
    "grid_search.fit(X_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate the Davies-Bouldin score for the test set\n",
    "db_score_test = davies_bouldin_score(X_test, y_pred)\n",
    "\n",
    "# Print the Davies-Bouldin score for the test set\n",
    "print(\"Davies-Bouldin Score for the test data:\", db_score_test)\n",
    "\n",
    "# Create a DataFrame to examine the distribution between clusters and actual labels\n",
    "data_with_predictions = pd.DataFrame({\n",
    "    'Prediction': y_pred,  # Predicted clusters\n",
    "    'Actual': y_test_labels.reset_index(drop=True)  # Original labels (0 or 1)\n",
    "})\n",
    "\n",
    "# Group by cluster prediction and actual label, then count occurrences\n",
    "distribution = pd.crosstab(data_with_predictions['Prediction'], data_with_predictions['Actual'])\n",
    "\n",
    "# Print the distribution matrix\n",
    "print(distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
